#+TITLE: ParaCuber Overview
#+AUTHOR: Max Heisinger

* Overview

This is an overview over the ParaCuber SAT Solver, a /distributed cube-and-conquer/ SAT Solver.
It is primarily based on the /CaDiCal/ CDCL Solver because of its good extensibility. New
features will be:

  - /Parallelising solving/ using a distributed cube-and-conquer approach.
  - Adding /network support/ to the solving framework.
  - Implementing efficient and distributed /performance debugging mechanisms/ to
    better understand bottlenecks in the solving pipeline.

** Main Properties of the Architecture

It is desired to create a primarily socket based communication framework that does 
not rely on direct memory access betweeen worker nodes. Direct memory access
/could/ be encoded on multiple instances running on the same node, but 
/cannot/ be done over multiple network nodes without expensive caching operations. If
a streaming encoding can be found, this would be better than to encode the entire
multi-host effort into shared memory accesses.

Multiple instances will be run in a coordinated effort. First, a normal CDCL solver is
started in parallel with the rest of the solving process. The other path through the solver
is done by generating a cube. This process is repeated on multiple instances of the solver
and guided by global heuristics shared between nodes and their parents.

#+BEGIN_SRC dot :file architecture.png
  digraph {
      "Formula" -> "Solve directly via CDCL" [label = "If heuristically easy"];
      "Formula" -> "Cube" [label = "If heuristically hard"];
      "Formula" -> "Offload" [label = "If current host utilization is > 90%"];
      "Solve directly via CDCL" -> "Formula";
      "Cube" -> "Formula";
      "Offload" -> "Formula";
  }
#+END_SRC

#+RESULTS:
[[file:architecture.png]]

** Source of Parallelism

Creating the cubes is the main source of parallelism. The rest is driven
in a portfolio style solver, by concurrently solving a problem via CDCL and 
nested cubes.

* Important Decisions to Make

** When to Split (How to Create Cubes)

This should work by dividing up the problem into equally
sized chungs of cubes or by finding decision spots that are
suitable for creating sub-problems.

** When To Distribute/Offload

This is the challenge of when to offload a task onto another
thread or an entirely different machine. This can be driven
by having global heuristics multicasted between all nodes
about the utilization of the solving cluster.

** When to Solve via CDCL

As soon as the heuristic deems another cube to be impractical.

** Sharing of Learnt Clauses?

Only clauses with /very/ high glucose levels could be shared
among all nodes. This can be done by multicasting to all receiving
nodes and applying the learnt clauses to the solving threads. Learnt clauses
would ideally be small, so a large range of conditions is covered.

This clause sharing has to be evaluated further by creating tests and benchmarks.

* Global Statistics and Mechanisms

Every node in the system needs to have knowledge about the state of the cluster.
This should be sent to all nodes all the time; a node receives an initial ID 
at start. A node can have multiple different problems running on it (which also makes it
into the statistics) and forwards its statistics to all other hosts in the system. There exists
no main master server, but everything is done peer-to-peer. The orchestrator is
the machine the user is working on, which analyses the results.

The following global statistics should be available for making decisions on 
individual nodes:  

  - Total number of Threads
  - Number of generated Cubes
  - Utilization
    - Based on number of available threads, number of running tasks and task queue average, minimum and maximum.

* Protocols and Ports

** Orchestration and Infrastructure - Port 10060

Nodes announce themselves periodically over a UDP broadcast on this port. This
is also used to announce changing statistics of a node. Every node has a UUID, which can
be persisted in a configuration file. This UUID is used to identify senders of 
messages. This way, multiple nodes (with multiple configurations) may run on the same hardware
and nodes are abstracted over network changes.

  - Node Availability Announcement (Statistics of node, available threads, memory, ...)
  - Node Statistics Update (Current Tasks in Queue, Cubes per Second, Utilization, ...)
  - Solving Update (SAT found, learnt clause announcement)

** Data Streams - Port 10061

Data Streams are TCP Streams created between nodes on a case-by-case basis. Once
a path in the solver tree decides to offload work based on the global statistics, 
it communicates with the node in question by opening (or re-opening) a TCP connection
and sending the desired work to be done. Once the data is transferred, the connection
can be closed or given to a connection pool to be closed later.

** Monitoring Streams - Port 10069

This is for development purposes. Monitoring streams may contain performance data.
Should be optional and not available by default.
